{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - LLM-Powered Clickbait Detector\n",
    "\n",
    "Part 3: Experiment with GPT-3.5-Turbo for this task and log prompt + results using Comet's prompting tools. Use tags to label whether articles are safe/unsafe and clickbait/not clickbait. Use CoT, few-shot and zero-shot prompting techniques and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import comet_llm\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Environment variable(s)\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "COMET_API_KEY = os.getenv(\"COMET_API_KEY\")\n",
    "os.environ[\"COMET_API_KEY\"] = COMET_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(max_retries=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(messages, model=\"gpt-3.5-turbo-1106\", temperature=0, max_tokens=300):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-Shot Template\n",
    "\n",
    "zero_shot_system_message = \"\"\"\n",
    "Your task is to detect if a given text is a Clickbait/Non-Clickbait and/or Safe/Unsafe.\n",
    "The user input is delimited by ```\n",
    "\n",
    "Your response should be either the headline is a \"Clickbait/Non-Clickbait\" and/or \"Safe/Unsafe\" ONLY and nothing else.\n",
    "\n",
    "Example Output: \n",
    "\n",
    "1. Clickbait, Safe\n",
    "2. Non-Clickbait\n",
    "3. Non-Clickbait, Unsafe\n",
    "4. Unsafe\n",
    "\n",
    "Text: {input}\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "user_message = \"\"\"\n",
    "Classify the following text: ```{user_input}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = [\n",
    "    (\"You won't believe what happened next - video inside!\", \"Clickbait\"),\n",
    "    (\"Is the moon actually made of cheese? The truth revealed!\", \"Clickbait\"),\n",
    "    (\"Doctors are stunned by this one weird trick to lose weight!\", \"Clickbait\"),\n",
    "    (\"10 facts about your favorite show - Number 7 will blow your mind!\", \"Clickbait\"),\n",
    "    (\"NASA to Launch New Mars Rover Next Month.\", \"Non-Clickbait\"),\n",
    "    (\"Federal Reserve Increases Interest Rates by 0.5%.\", \"Non-Clickbait\"),\n",
    "    (\"Recent Studies Show Coffee May Have Health Benefits.\", \"Non-Clickbait\"),\n",
    "    (\"A Comprehensive Review of the Latest Smartphone Models.\", \"Non-Clickbait\"),\n",
    "    (\"UN Climate Summit to Begin in Paris Next Week.\", \"Non-Clickbait\"),\n",
    "    (\"How to Make Homemade Explosives!\", \"Unsafe\"),\n",
    "    (\"The Secret Art of Digital Hacking - A Guide!\", \"Unsafe\"),\n",
    "    (\"10 Easy Ways to Commit Fraud and Get Rich Quick!\", \"Unsafe\"),\n",
    "    (\"Why Vaccines are the Biggest Scam in Medical History!\", \"Unsafe\"),\n",
    "    (\"Join the Underground Rebellion Against Government Control!\", \"Unsafe\"),\n",
    "    (\"10 celebrities who hate each other - Number 5 will make you gasp!\", \"Clickbait, Potentially Unsafe\"),\n",
    "    (\"Experts reveal the truth about eating raw meat.\", \"Non-Clickbait, Potentially Unsafe\"),\n",
    "    (\"The hidden dangers of everyday items in your home!\", \"Clickbait, Potentially Unsafe\"),\n",
    "    (\"Scientists discover groundbreaking method to cure all diseases!\", \"Clickbait\"),\n",
    "    (\"The Untold Truth About the World's Secret Societies!\", \"Clickbait, Potentially Unsafe\"),\n",
    "]\n",
    "\n",
    "validation = [\n",
    "    (\"35 Celebs Who Knew Each Other Before They Were Famous\", \"Clickbait\"),\n",
    "    (\"16 Important Questions Millennials Have For Gen Z'ers\", \"Clickbait, Safe\"),\n",
    "    (\"Inside Day Cares, Post-Covid\", \"Non-Clickbait\"),\n",
    "    (\"Casa Dani, From a Michelin Chef, to Open in Manhattan West\", \"Non-Clickbait, Safe\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(prompt_template, inputs):\n",
    "\n",
    "    responses = []\n",
    "\n",
    "    for i in range(len(inputs)):\n",
    "        messages = messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt_template.format(input=inputs[i])\n",
    "            }\n",
    "        ]\n",
    "        response = get_completion(messages)\n",
    "        responses.append(response)\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot Template Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your task is to identify the category of the following text:\n",
      "\n",
      "Clickbait/Non-Clickbait: Is the text intended to sensationalize and attract clicks rather than inform?\n",
      "Safe/Unsafe: Does the text contain potentially harmful information or promote harmful actions?\n",
      "\n",
      "The user input is delimited by ```\n",
      "\n",
      "Your response should be either the headline is a \"Clickbait/Non-Clickbait\" and/or \"Safe/Unsafe\" ONLY and nothing else\n",
      "\n",
      "\n",
      "Text: Doctors are stunned by this one weird trick to lose weight!\n",
      "Output: Clickbait\n",
      "\n",
      "Text: How to Make Homemade Explosives!\n",
      "Output: Unsafe\n",
      "\n",
      "Text: 10 facts about your favorite show - Number 7 will blow your mind!\n",
      "Output: Clickbait\n",
      "\n",
      "\n",
      "Text: {input}\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_few_shot_template(few_shot_prefix, few_shot_suffix, few_shot_examples):\n",
    "    \"\"\"Constructs the few-shot template.\"\"\"\n",
    "    example_texts, example_outputs = zip(*few_shot_examples)  # Unpack examples into text and output pairs\n",
    "    formatted_examples = \"\\n\".join(f\"Text: {text}\\nOutput: {output}\\n\" for text, output in zip(example_texts, example_outputs))\n",
    "    return f\"\"\"{few_shot_prefix}\n",
    "\n",
    "{formatted_examples}\n",
    "\n",
    "{few_shot_suffix}\"\"\"\n",
    "\n",
    "def random_sample_data(data, n):\n",
    "    \"\"\"Samples n random examples from the data.\"\"\"\n",
    "    flattened_headlines = np.array([headline[0] for headline in data])\n",
    "    random_indices = np.random.choice(len(flattened_headlines), n, replace=False)\n",
    "    random_headlines = flattened_headlines[random_indices]\n",
    "    random_categories = [data[index][1] for index in random_indices]\n",
    "    return zip(random_headlines, random_categories)\n",
    "\n",
    "few_shot_prefix = \"\"\"\n",
    "Your task is to identify the category of the following text:\n",
    "\n",
    "Clickbait/Non-Clickbait: Is the text intended to sensationalize and attract clicks rather than inform?\n",
    "Safe/Unsafe: Does the text contain potentially harmful information or promote harmful actions?\n",
    "\n",
    "The user input is delimited by ```\n",
    "\n",
    "Your response should be either the headline is a \"Clickbait/Non-Clickbait\" and/or \"Safe/Unsafe\" ONLY and nothing else\n",
    "\"\"\"\n",
    "\n",
    "few_shot_suffix = \"\"\"Text: {input}\\nOutput:\"\"\"\n",
    "\n",
    "few_shot_template = get_few_shot_template(few_shot_prefix, few_shot_suffix, random_sample_data(headlines, 3))\n",
    "\n",
    "print(few_shot_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain logged to https://www.comet.com/sachs7/llm-general\n"
     ]
    }
   ],
   "source": [
    "few_shot_predictions = get_predictions(few_shot_template, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_predictions = get_predictions(zero_shot_system_message, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clickbait, Safe', 'Clickbait, Safe', 'Non-Clickbait, Safe', 'Non-Clickbait, Safe']\n",
      "['Clickbait', 'Clickbait, Safe', 'Non-Clickbait', 'Non-Clickbait, Safe']\n"
     ]
    }
   ],
   "source": [
    "print(zero_shot_predictions)\n",
    "print(few_shot_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clickbait', 'Clickbait, Safe', 'Non-Clickbait', 'Non-Clickbait, Safe']\n"
     ]
    }
   ],
   "source": [
    "expected_output = [val[1] for val in validation]\n",
    "print(expected_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM-Powered Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm-powered evaluation\n",
    "\n",
    "system_prompt = \"\"\"\"\n",
    "You are a teacher grading a prediction.\n",
    "You will be given the expected answer (delimited by ```) and the output from a prediction (delimited by ###).\n",
    "Your task is to grade the model. You will output either 'CORRECT' or 'INCORRECT' for each question.\n",
    "\n",
    "Grade the prediction as 'CORRECT' if the model's prediction overlaps with the expected answer.\n",
    "The order of the items in each answer is also not a problem.\n",
    "The model's prediction is 'CORRECT' as long as the expected answer is present in the model's prediction.\n",
    "\n",
    "Grade the prediction as 'INCORRECT' if the model's prediction doesn't overlap with the expected answer.\n",
    "\n",
    "Here are the expected answer:\\n```{expected_answers}```\n",
    "\n",
    "Here are the model's prediction:\\n###{predictions}###\n",
    "\n",
    "Output will be: <Clickbait> or <Clickbait, Safe> or <Non-Clickbait, Safe>  or <Unsafe> etc...\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# function to get the final llm grading\n",
    "def get_llm_grading(expected_answers, predictions, system_prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt.format(expected_answers=expected_answers, predictions=predictions)\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=256,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# run the llm grading using the predictions obtained before\n",
    "zero_shot_eval_predictions = [get_llm_grading(expected_output[i], zero_shot_predictions[i], system_prompt) for i in range(len(expected_output))]\n",
    "few_shot_eval_predictions = [get_llm_grading(expected_output[i], few_shot_predictions[i], system_prompt) for i in range(len(expected_output))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CORRECT', 'CORRECT', 'INCORRECT', 'CORRECT']\n",
      "['CORRECT', 'CORRECT', 'CORRECT', 'CORRECT']\n"
     ]
    }
   ],
   "source": [
    "print(zero_shot_eval_predictions)\n",
    "print(few_shot_eval_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log to Comet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log prediction for both few-shot and zero-shot using Comet\n",
    "import comet_llm\n",
    "\n",
    "comet_llm.init(project=\"tagger-llm-evaluator\", api_key=COMET_API_KEY)\n",
    "\n",
    "for i in range(len(validation)):\n",
    "    # log zero-shot predictions\n",
    "    comet_llm.log_prompt(\n",
    "        prompt = system_prompt.format(expected_answers=expected_output[i], predictions=zero_shot_predictions[i]),\n",
    "        tags = [\"gpt-3.5-turbo-1106\", \"zero-shot\"],\n",
    "        metadata = {\n",
    "            \"model_name\": \"gpt-3.5-turbo-1106\",\n",
    "            \"temperature\": 0,\n",
    "            \"expected_output\": expected_output[i],\n",
    "            \"model_output\": zero_shot_predictions[i]\n",
    "        },\n",
    "        output = zero_shot_eval_predictions[i]\n",
    "    )\n",
    "\n",
    "    # log few-shot predictions\n",
    "    comet_llm.log_prompt(\n",
    "        prompt = system_prompt.format(expected_answers=expected_output[i], predictions=few_shot_predictions[i]),\n",
    "        tags = [\"gpt-3.5-turbo-1106\", \"few-shot\"],\n",
    "        metadata = {\n",
    "            \"model_name\": \"gpt-3.5-turbo-1106\",\n",
    "            \"temperature\": 0,\n",
    "            \"expected_output\": expected_output[i],\n",
    "            \"model_output\": few_shot_predictions[i]\n",
    "        },\n",
    "        output = few_shot_eval_predictions[i]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comet View\n",
    "\n",
    "Results of Few-Shot:\n",
    "\n",
    "![1-Few-Shot-Tag](images/1-few-shot.png)\n",
    "\n",
    "\n",
    "Results of Zero-Shot:\n",
    "\n",
    "![2-Zero-Shot-Tag](images/2-zero-shot.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
